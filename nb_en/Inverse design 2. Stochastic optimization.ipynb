{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a3ba2b9",
   "metadata": {},
   "source": [
    "MIT Licence\n",
    "\n",
    "© Alexey A. Shcherbakov, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ffec2d",
   "metadata": {},
   "source": [
    "# Lecture 5.2. Stochastic optimization\n",
    "\n",
    "The gradient methods mentioned in the previous lecture work well in situations where there is a good approximation to the global extremum, or when the objective function has a sufficiently large number of local extrema, which, nevertheless, are satisfactory solutions to the considered practical problem. The latter argument determines the frequent use of such deterministic methods in practice. However, there are situations when a good initial approximation is unknown, and the enumeration of solutions obtained on the basis of various initial data turns out to be too resource-intensive. In these situations, various stochastic optimization algorithms are used, which, similar to deterministic ones, may or may not use information about the gradients of the objective function. Unlike deterministic methods, where it is better to use the gradient calculation where possible, there are a number of popular stochastic approaches based only on the evaluation of the objective function itself, which have found wide application. In this lecture, we will consider such methods.\n",
    "\n",
    "Stochasticity means that when solving an optimization problem, random variables are calculated, either in the objective function or within the algorithm. Randomness in the objective function means that the evaluation of possible solutions allows for uncertainty or noise. Randomness in the algorithm is used to increase the probability of finding global optima or better local optima.\n",
    "\n",
    "Local optimization algorithms in the presence of noise include random search methods (Random Search, Stochastic Hill Climbing), stochastic gradient search (SGD) and its various modifications (e.g., Adam, RMSprop, Adagrad), stochastic quasi-Newton methods (oLBFGS, SQN). Some of these methods for some problems allow one to effectively find global extrema. In general, other methods are used to search for global optima, including evolutionary algorithms (genetic algorithms, differential evolution), particle swarm optimization, ant colony optimization, and stochastic simulated annealing. Gradient-free methods include random search methods and evolutionary strategies.\n",
    "\n",
    "For optical and photonic devices, the sets of parameters to be optimized typically include the geometry and physical parameters of the problem, and the objective functions must take into account the required functionality, as illustrated in the figure below.\n",
    "\n",
    "<figure> <center>\n",
    "<img src=\"https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41566-018-0246-9/MediaObjects/41566_2018_246_Fig1_HTML.png?as=webp\" width=\"1000\">\n",
    "<br><caption><a href=\"https://www.nature.com/articles/s41566-018-0246-9\">Optical systems engineering.</a></p></caption>\n",
    "</center> </figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab869914",
   "metadata": {},
   "source": [
    "## Some algorithms of stochastic optimization\n",
    "\n",
    "### Genetic algorithms\n",
    "\n",
    "The idea of ​​genetic algorithms, like other evolutionary algorithms, is based on the imitation of natural selection. Here, such operations as crossing (crossover), mutation and selection are applied to the vectors of parameters to be optimized. The vectors themselves are called gene vectors (genotypes), so that each element can be a bit, a number or some object. The algorithm is initialized with a set of randomly assigned genotypes, which are evaluated using the objective function (here the name fitness function is used). Then, taking into account the fitness value, the best solutions are selected, to which crossing and mutation operations are applied, resulting in new solutions. For these new solutions, the fitness function is calculated and selection is carried out into a new generation. Then the process is repeated.\n",
    "\n",
    "<figure> <center>\n",
    "<img src=\"https://blogger.googleusercontent.com/img/a/AVvXsEit9z8U-EGapaHDVzob0mCLlbu2VuGDR7n1q9cszlhDfyIecCWG6xOiJxy2In0_ygEpuEdXJAZ1U-gU4avJ92uNoCT_n8ugZEG8bHWutUWWY117fPZ4zYP9p-e-VC9GzYhCNnQxEZ3rpxz78CU1eobLEusWE5M5cdt5_tYIhxIdaqkpE2nL6tPZh8Vr3g=w640-h374\" width=\"500\">\n",
    "<br><caption><a href=\"https://www.ntirawen.com/2022/02/genetic-algorithm-in-artificial.html\">Иллюстрация шагов генетического алгоритма.</a></p></caption>\n",
    "</center> </figure>\n",
    "\n",
    "### Evolutionary strategies\n",
    "\n",
    "The main difference between evolutionary strategies and genetic algorithms is that they operate with vectors of real numbers. When searching for a solution, mutation and crossbreeding are first used, followed by deterministic selection from the generation of offspring (and possibly parents). Mutation is often the addition of a normally distributed random variable to each component of the vector. Differential evolution algorithms use a hybrid approach, in which new individuals are obtained through a linear combination of existing ones.\n",
    "\n",
    "### Particle swarm optimization\n",
    "\n",
    "In swarm methods, each element of the vector of parameters to be optimized is associated with the position of some particle. Also, each particle in the swarm has some velocity. At each step, the particles are shifted to a new position, the objective function for the swarm particles is calculated, the best states of each individual particle and all particles are compared with the current values ​​based on the objective function values, and the particle velocities are updated depending on their state.\n",
    "\n",
    "<figure> <center>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/e/ec/ParticleSwarmArrowsAnimation.gif?20170112115133\" width=\"500\">\n",
    "<br><caption><a href=\"https://en.wikipedia.org/wiki/Particle_swarm_optimization\">Иллюстрация метода роя частиц.</a></p></caption>\n",
    "</center> </figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6acd51",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "1. Fouskakis, D., Draper, D. [Stochastic Optimization: a Review. International Statistical Review](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1751-5823.2002.tb00174.x), 70(3), 315–349 (2002)\n",
    "2. [Introduction to Genetic Algorithms in Python](https://algodaily.com/lessons/introduction-to-genetic-algorithms-in-python)\n",
    "3. Rasmus E. Christiansen and Ole Sigmund, [Inverse design in photonics by topology optimization: tutorial](https://opg.optica.org/josab/fulltext.cfm?uri=josab-38-2-496&id=446780), J. Opt. Soc. Am. B 38, 496-509 (2021)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
